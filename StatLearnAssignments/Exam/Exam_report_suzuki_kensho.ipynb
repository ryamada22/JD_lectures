{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### レビュー論文を読むにあたって、講義で得た知識がどのように役に立ったか\n",
    "\n",
    "- 論文全体を通して、講義で行なったデータセットがどのようなものであるか、機械学習の大まかな手順を意識できていたので、しっかりとしたイメージを持つことができた点。\n",
    ">特にTips 1,2では、データの前処理(整形)に関してであったので、著者が述べているデータへの操作そのものと、その意味をつかむことが容易でした。\n",
    "また、Tips 3以降では、問題のカテゴリーを決めることから始まり、アルゴリズムの選択、ハイパーパラメータのチューニング手法(グリッドサーチ)、精度の検定、過学習抑制(クロスバリデーション、正則化)について言及していたが、所々で機械学習の実例をあげた説明や、実際の手法を挙げている箇所があり、講義で触れた手法を頭の中で実例にして読むことで、機械学習をするにあたって必要なことを理解する補助となりました。\n",
    "\n",
    "\n",
    "- バイアス、バリアンスの知識は、データセットを、学習用・バリデーション用・テスト用とに分けることや、クロスバリデーションにおいて、単純に精度を向上させ、過学習を防ぐ意義があるという理解だけでなく、データセットごとの特徴や傾向に意識を向け、なぜ精度改善のためにこれらの操作を行うのかの理解。\n",
    "\n",
    "- ハイパーパラメータとはどういったものか、予めknnやSVM(カーネル関数)で学習した知識があったため、ハイパーパラメータのチューニングに関して確固とした見識。\n",
    "\n",
    "- 過学習の抑制で説明されていた、正則化について論文中ではほとんど説明はなかったが、正則化の種類やそれぞれの特徴についての講義があったため、なぜ過学習が抑制できるのかを理解していたことは、tipsを丸暗記するより効果的な知見となった点。\n",
    "\n",
    "まとめると、講義で受けた内容は、機械学習を行う上で、論文で述べられているtipsが何故必要なのか、どのようにして役に立つのかを暗記するだけでなく、実例を交えて、その本質を理解する扶翼となりました。\n",
    "また、論文の内容をより拡張させた理解に及ぶことができ、その延長線として講義が役立ちました。\n",
    "\n",
    "\n",
    "### 論文を読む上で、講義に必要であったと思われる内容\n",
    "\n",
    "- 予測モデルを評価する(精度を測定する)点において、論文ではAUC(ROC vs PR curve), MCCなどの手法が挙げられていたが、それらに焦点を当てた講義(fisher's exact testの講義はありましたが、機械学習のモデル評価と結びつけた内容はなかったかと思います)\n",
    "\n",
    "- また、ハイパーパラメータの最適化手法についても、バイアス、バリアンスに則った調整が必要だという説明があったが、実際の手法(グリッドサーチ、ベイズ最適化など)に触れる講義\n",
    "\n",
    "以上、2点があればと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
