# 9章: 加法的モデル、木、関連手法
次元呪いを回避する手法の紹介とのこと(逆に言うと8章以前の手法は次元の呪いを回避できないという文面に見える)

# 9.1 一般的加法モデル
(一般化されていない)加法モデルに対応するのが線型回帰モデル(Y = β + β_1 * X_1 + β-2 * X_2 + ...)で、このXの代わりにノンパラメトリックかつ滑らかな関数で置き換えたものが一般的加法モデル(E(y|x_1, ... , x_p) = α + f_1(x-1) + ... + f_p(x_p), where f is some noparametric smooth function)である。


線形モデルは非線形性を表現しきれない場合があるが、一般的加法的モデル(generalized additive model, GAM)は非線形性を自動的に表現できる。
リンク関数: E()の部分で平均を計算する関数を変化させることが考えられるが、変化させる関数(g(μ))をリンク関数という。加法部分も色々の拡張がある
セミパラメトリックモデル: g(μ) = X^{T} + α + f(Z)
その他のモデル: g(μ) = f(X) + g(Z), f(X) + g(Z,W)

## 9.1.1 加法的モデルの当てはめ
アルゴリズム9.1の実装は2段階で行う必要がある
1. Sj(文中ではSmoothing operator)とされるの実装
2. アルゴリズム9.1を好きな言語で逐次翻訳
  ステップ2の2番目の処理は関数の差になっているが、関数と係数行列の対応が取れるようなので、係数行列の差を求めれば良いか(これが正しければ最終的に収束した後はこの係数行列を使って関数の値を返せる)

Smoothing operatorとされるもののinputは滑らかにしたい関数ではなく(のように当初誤解していて混乱した)、滑らかになるようにつないで欲しいデータ点群(X)になる。
このアルゴリズムは必要となればhttps://web.archive.org/web/20190415063953/http://swdrsker.hatenablog.com/entry/2018/08/14/182915やhttps://web.archive.org/web/20190415064006/https://myenigma.hatenablog.com/entry/2016/10/12/073335などで解説されているので適宜参照する

## 9.1.2 例: 加法的ロジスティック回帰
ロジスティック回帰を上記の定義に従って一般化したもの
ロジスティック回帰自体は4.4に説明あり、0・1の2値問題で利用される
具体的な内容は時間がないので略
