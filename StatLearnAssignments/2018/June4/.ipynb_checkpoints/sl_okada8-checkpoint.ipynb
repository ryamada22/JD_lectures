{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even for learning data that can not be linearly separated, there is a possibility that linear separation becomes possible by mapping to high dimensional space using kernel trick.\n",
    "\n",
    "This is the example of the mapping from two dimension to three dimension.\n",
    "\n",
    "$$\n",
    "\\phi(x_1,x_2)=(z_1,z_2,z_3)=(x_1,x_2,{x_1}^2+{x_2}^2)\n",
    "$$\n",
    "\n",
    "The innner product in the high dimensional space, that is ${\\phi(x^{(i)})}^T \\phi(x^{(j)}), which are expressed using kernel function.\n",
    "\n",
    "Without obtaining the feature vector in the high dimensional space, directly from the kernel function, the inner product of the feature vector in the high dimensional space can be estimated. The method to find is a kernel trick.\n",
    "It is expredded as:\n",
    "\n",
    "$$\n",
    "k(x^{(i)},x^{(j)})={\\phi(x^{(i)})}^T{\\phi(x^{(j)})}\n",
    "$$\n",
    "\n",
    "As an example of the kernel function, there is a Gaussian kernel expressed by the following equation.\n",
    "Using the feature vector in the original space, it can be calculated by the following expression.\n",
    "\n",
    "$$\n",
    "k(x^{(i)},x^{(j)})=exp(-\\frac{||x^{(i)}-x^{(j)}||^2}{2{\\sigma}^2})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
