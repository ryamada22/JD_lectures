{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Bias\n",
    "\n",
    "Bias is the deviance between true value and estimation.\n",
    "\n",
    "+ Variance\n",
    "\n",
    "Variance is the performance of estimation of test data or unknown data. The more complex model generally cannot fit well (overfitting).\n",
    "\n",
    "Too complex model can explain the given data, but it cannot explain new data.\n",
    "\n",
    "Too loose data cannot explain the given data, but it can explain new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "Linear regression\n",
    "\n",
    "Assignment 課題\n",
    "+ The estimated two coefficients minimize the sum of squares (least squares) between estimated values and sample values. We can freely change the values of two coefficients (\"Free Parameters\"). You can assign two \"Parameters\" as two \"Coodinate\" axes.\n",
    "\n",
    "+ Generate grid points of the parameter space and calculate sum of squares, which generate curved surface over two \"Dimensional\" space.\n",
    "\n",
    "Polynomial interpolation\n",
    "\n",
    "Assignment 課題\n",
    "+ How many coefficients should be determined?\n",
    "+ Check the deviation of samples from the curves become smaller with the model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [938.23786125]\n",
      "Mean squared error: 2548.07\n",
      "Variance score: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/matplotlib/collections.py:549: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show(block=False)\n",
    "\n",
    "\n",
    "xt = regr.intercept_\n",
    "yt = regr.coef_\n",
    "vt = mean_squared_error(diabetes_y_train, regr.predict(diabetes_X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152.91886182616167"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import matplotlib\n",
    "import scipy.stats as st\n",
    "\n",
    "iter = 100\n",
    "x = np.linspace(0, 200, num=iter) # intercept\n",
    "y = np.linspace(0, 3000, num=iter) # coef\n",
    "\n",
    "value = []\n",
    "for (x0, y0) in zip(x, y):\n",
    "    regr.coef_ = np.array([y0])\n",
    "    regr.intercept_ = np.array([x0])\n",
    "    value += [mean_squared_error(diabetes_y_train, regr.predict(diabetes_X_train))]\n",
    "\n",
    "value = []\n",
    "xx = np.repeat(x, iter)\n",
    "yy = np.concatenate(np.repeat(y, iter).reshape(iter, iter).T)\n",
    "for x0 in x:\n",
    "    for y0 in y:\n",
    "        regr.coef_ = np.array([y0])\n",
    "        regr.intercept_ = np.array([x0])\n",
    "        value += [mean_squared_error(diabetes_y_train, regr.predict(diabetes_X_train))]\n",
    "\n",
    "value = np.array(value)\n",
    "\n",
    "cols = matplotlib.cm.rainbow(np.linspace(0, 1, len(value)))\n",
    "\n",
    "plt.scatter(xt, yt, s=1000, c=\"r\", label='the data')\n",
    "plt.scatter(xx, yy, c=cols[np.argsort(value)], s=10, label='the data')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "polynomial interpolation\n",
    "\n",
    "+ How many coefficients should be determined?\n",
    "degrees + 1\n",
    "\n",
    "+ Check the deviation of samples from the curves become smaller with the model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 9.737418462948854\n",
      "4 3.7897113794973025\n",
      "5 0.7991795079668366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/matplotlib/collections.py:549: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\" function to approximate by polynomial interpolation\"\"\"\n",
    "    return x * np.sin(x)\n",
    "\n",
    "\n",
    "# generate points used to plot\n",
    "x_plot = np.linspace(0, 10, 100)\n",
    "\n",
    "# generate points and keep a subset of them\n",
    "x = np.linspace(0, 10, 100)\n",
    "rng = np.random.RandomState(0)\n",
    "rng.shuffle(x)\n",
    "x = np.sort(x[:20])\n",
    "y = f(x)\n",
    "\n",
    "# create matrix versions of these arrays\n",
    "X = x[:, np.newaxis]\n",
    "X_plot = x_plot[:, np.newaxis]\n",
    "\n",
    "colors = ['teal', 'yellowgreen', 'gold']\n",
    "lw = 2\n",
    "plt.plot(x_plot, f(x_plot), color='cornflowerblue', linewidth=lw,\n",
    "         label=\"ground truth\")\n",
    "plt.scatter(x, y, color='navy', s=30, marker='o', label=\"training points\")\n",
    "\n",
    "for count, degree in enumerate([3, 4, 5]):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "    model.fit(X, y)\n",
    "    y_plot = model.predict(X_plot)\n",
    "    print(degree, mean_squared_error(y, model.predict(X)))\n",
    "    plt.plot(x_plot, y_plot, color=colors[count], linewidth=lw,\n",
    "             label=\"degree %d\" % degree)\n",
    "\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.737418462948854"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y, model.predict(X))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
