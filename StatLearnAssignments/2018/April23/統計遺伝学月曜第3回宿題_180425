<統計遺伝学月曜20180423>
<Bias Variance Tradeoffに関して>
バイアスバリアンストレードオフに関して、新しく機械学習を始めた人に説明しなさい。
「今、説明のために予測を目的とする。真理に近い予測をするために、大きく二つの方法があると考える。
予測のために最小二乗法を基に発展してきた統計学と、複雑な条件(複雑な関数など)を設定して予測を行う機械学習の二つである。
最小二乗法に基づく予測は、直線を引くだけのシンプルな方法(の拡張)である。この理論に基づくと、いつまで経っても真の予測をすることはできないかもしれないが、一方で大きく外すことはない。つまりサンプル数が大きくなってもバイアスは取り去れない。
一方で機械学習による予測は、詳細な条件を設定するため、現在手元にある標本のサンプル数がかなり大きい場合には精度の高い予測が可能となるが、サンプル数が少ない場合にはかなり様相の異なる予測結果となる(外れ値などに大きく左右される)可能性がある。つまりサンプル数が大きくなるとバイアスは小さくなる
どちらが良いというのは目的と手元のデータセットに依存するため一概に言えない。」
※　予習・授業では楕円を用いて、サンプル数を調整して実演を行った。

今回の宿題では、
ラベル値を推測するために多くのサンプルセットを作成し、その平均をとったが我々の設定した真実とは異なる結果が出た。
これはkNNなどが、分散(バリアンス)が高いアルゴリズムである事が影響している。
自分の理解では、分散が高いとランダムに発生したノイズをアルゴリズムでモデル化してしまうため複雑さ故に間違えてしまう可能性が出てくる。
