＜統計遺伝学月曜2018年4月16日の課題＞
・How to evaluate learning results and learning methods：
・Training set and test set：モデル形成のためのデータセットと、そのモデルを評価するためのデータセット
・Bias and variance：
真の値と予測された値の誤差は3つに分類される
①バイアス：モデルが単純であるあまりに学習が上手くいかない度合い。(未学習に対する指標）
②バリアンス：訓練データに依存しすぎることで新しいデータへの予測が悪化する度合い。（過学習に対する指標)
③誤差の分散(ノイズ)
に分解できる
・Bias-Variance tradeoff：単純なモデルは学習に用いるサンプルが変化しても関数の形は大きく変わらないが（Low Variance）、誤差（真の値とのズレ）が大きい（High Variance）。
複雑なモデルは逆に、学習に用いるサンプルが変化すると関数の形が大きく変わり説明力が上がる（High Variance）が、その分誤差は小さくなる（Low Variance）
・Overfitting：過学習→（説明変数が多いなど）もとのデータセットを説明する力が高すぎて外的妥当性に乏しくなる
・Model complexity：モデルの複雑さ→過学習につながる

* Report your opinion on the classification displayed in the bottom drawing in the document "Linear Models and Least Squares"
1.　かなりはっきり分かれていないと正確に分類する事ができない。
2.　分散(ばらつき)が多いほど間違えた分類が多い
3.　linearでは工夫による限界が早い(更なる工夫がしにくい)

* Describe the top formula in the document "k-Nearest Neighbor Method" in your mother tongue language as if you describe it to the friends who are not familiar with math.
Nk(x)は与えたxという位置(値)から最も近いxiをk個取り出したものである。それに該当するyiを足してkで割る(つまり平均をとる)値と定義される。
簡単にいうと、「与えられたデータの一番近くからk個分の結論を持ってきて、平均を求める。するとそれが与えられたデータの結論に近いだろうと考える」という事。

* Describe the bottom 9 panels in the document "k-Nearest Neighbor Method" on the change in the regions along the parameter values of k.
1. kが小さいと外れ値の影響を受けやすくなる(特にk=1)
2. kが大きくなるにつれて区分けとしてはsimpleな線で表しやすくなる
3. k=100などNに比して大きくなると、「全ての平均を表しているだけ」に近づいていく
