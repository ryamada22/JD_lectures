{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Ideas in Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to evaluate learning results and learning methods\n",
    "Learning results and methods are evaluated by the error they produced after testing\n",
    "\n",
    "### Training set and test set\n",
    "Training set is the data set used for prediction while Test set is the data set used to measure the prediction accuracy\n",
    "\n",
    "### Bias and Variance\n",
    "Bias is the difference between predicted result and test data while variance is the sensitivity of model regarding the input data\n",
    "\n",
    "### Bias-Variance Tradeoff\n",
    "The dilemma where in order to create a prediction. High bias but low variance tend to appear in model with low complexity while low bias high variance tend to appear in model with high complexity.\n",
    "\n",
    "### Overfitting\n",
    "Overfitting is when the model has high training set accuracy but poorly predict outcomes using the test data.\n",
    "\n",
    "### Model complexity\n",
    "The ability of model to adapt to given training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opinion on Least-Square Based Classification Method\n",
    "A classification method that divides the data into groups using rigid divider (i.e. straight line) that derived by minimizing the sum of the square error. Based on the classification sample given, the Least-Square Based Classification method gave a very generalized yet rigid classification. Due to this characteristic, this classification method may introduce high classification error in data clusters with narrow mean range.\n",
    "\n",
    "## k-NN Classification Method Description\n",
    "The value of x is estimated using the average of k closest numbers from value similar to x that are previously known.\n",
    "\n",
    "## Describing The Effect of Change in k for k-NN Classification\n",
    "In the given diagram, black dots represent data classified as \"Green\" and red dots represent data clasified as \"Blue\". As the value of k increases the \"Green\" area reduces and start to yield missclassification among the tranining data set. Large value of k will favor the majority of data due to the nature of k-NN classification. As shown in the k=100, where almost all the black dots are classified as green."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
